{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "rIfe33d7Sss4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmWMmHrSnD2E",
        "outputId": "f4c3c722-3915-4462-b93e-09f5a80fbe2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQu7ySivXXm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f63f71eb-a381-4980-b6b5-75f1d1ef59c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1213, 82)\n",
            "Index(['participant_id', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV',\n",
            "       'APQ_P_APQ_P_OPD', 'SDQ_SDQ_Conduct_Problems',\n",
            "       'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems',\n",
            "       'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact',\n",
            "       'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing',\n",
            "       'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'ADHD_Outcome', 'Sex_F',\n",
            "       'Basic_Demos_Enroll_Year_2015', 'Basic_Demos_Enroll_Year_2016',\n",
            "       'Basic_Demos_Enroll_Year_2017', 'Basic_Demos_Enroll_Year_2018',\n",
            "       'Basic_Demos_Enroll_Year_2019', 'Basic_Demos_Enroll_Year_2020',\n",
            "       'Basic_Demos_Study_Site_1', 'Basic_Demos_Study_Site_2',\n",
            "       'Basic_Demos_Study_Site_3', 'Basic_Demos_Study_Site_4',\n",
            "       'PreInt_Demos_Fam_Child_Ethnicity_0.0',\n",
            "       'PreInt_Demos_Fam_Child_Ethnicity_1.0',\n",
            "       'PreInt_Demos_Fam_Child_Race_0.0', 'PreInt_Demos_Fam_Child_Race_1.0',\n",
            "       'PreInt_Demos_Fam_Child_Race_2.0', 'PreInt_Demos_Fam_Child_Race_3.0',\n",
            "       'PreInt_Demos_Fam_Child_Race_4.0', 'PreInt_Demos_Fam_Child_Race_7.0',\n",
            "       'PreInt_Demos_Fam_Child_Race_8.0', 'PreInt_Demos_Fam_Child_Race_9.0',\n",
            "       'MRI_Track_Scan_Location_1.0', 'MRI_Track_Scan_Location_2.0',\n",
            "       'MRI_Track_Scan_Location_3.0', 'MRI_Track_Scan_Location_4.0',\n",
            "       'MRI_Track_Scan_Location_all_zero_dummy', 'Barratt_Barratt_P1_Edu_12.0',\n",
            "       'Barratt_Barratt_P1_Edu_15.0', 'Barratt_Barratt_P1_Edu_18.0',\n",
            "       'Barratt_Barratt_P1_Edu_21.0', 'Barratt_Barratt_P1_Edu_3.0',\n",
            "       'Barratt_Barratt_P1_Edu_6.0', 'Barratt_Barratt_P1_Edu_9.0',\n",
            "       'Barratt_Barratt_P1_Edu_all_zero_dummy', 'Barratt_Barratt_P1_Occ_0.0',\n",
            "       'Barratt_Barratt_P1_Occ_10.0', 'Barratt_Barratt_P1_Occ_15.0',\n",
            "       'Barratt_Barratt_P1_Occ_20.0', 'Barratt_Barratt_P1_Occ_25.0',\n",
            "       'Barratt_Barratt_P1_Occ_30.0', 'Barratt_Barratt_P1_Occ_35.0',\n",
            "       'Barratt_Barratt_P1_Occ_40.0', 'Barratt_Barratt_P1_Occ_45.0',\n",
            "       'Barratt_Barratt_P1_Occ_5.0', 'Barratt_Barratt_P1_Occ_all_zero_dummy',\n",
            "       'Barratt_Barratt_P2_Edu_12.0', 'Barratt_Barratt_P2_Edu_15.0',\n",
            "       'Barratt_Barratt_P2_Edu_18.0', 'Barratt_Barratt_P2_Edu_21.0',\n",
            "       'Barratt_Barratt_P2_Edu_3.0', 'Barratt_Barratt_P2_Edu_6.0',\n",
            "       'Barratt_Barratt_P2_Edu_9.0', 'Barratt_Barratt_P2_Edu_all_zero_dummy',\n",
            "       'Barratt_Barratt_P2_Occ_0.0', 'Barratt_Barratt_P2_Occ_10.0',\n",
            "       'Barratt_Barratt_P2_Occ_15.0', 'Barratt_Barratt_P2_Occ_20.0',\n",
            "       'Barratt_Barratt_P2_Occ_25.0', 'Barratt_Barratt_P2_Occ_30.0',\n",
            "       'Barratt_Barratt_P2_Occ_35.0', 'Barratt_Barratt_P2_Occ_40.0',\n",
            "       'Barratt_Barratt_P2_Occ_45.0', 'Barratt_Barratt_P2_Occ_5.0',\n",
            "       'Barratt_Barratt_P2_Occ_all_zero_dummy', 'ADHD_Outcome_0',\n",
            "       'ADHD_Outcome_1', 'Sex_F_0', 'Sex_F_1'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#get tabular data\n",
        "import pandas as pd\n",
        "data_tabular= pd.read_csv(\"/content/drive/MyDrive/Datathon 2025 shared space/Data/merged_training_data_final.csv\")\n",
        "print(data_tabular.shape)\n",
        "print(data_tabular.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop global features\n",
        "#data_tabular.drop(columns=[\"subject\", \"wiener\", \"avg_path\", \"stoer_wagner_cut\", \"dijkstra_path_len\", \"matching_size\", \"barycenter_count\", \"cut_size\", \"conductance\", \"random_cut\"], inplace=True)\n",
        "#drop non-significant features\n",
        "data_tabular.drop(columns=[col for col in data_tabular.columns if col.startswith(\"MRI_Track_Scan_\")], inplace=True)\n",
        "data_tabular.drop(columns=[\"ADHD_Outcome_1\", \"ADHD_Outcome_0\", \"Sex_F_0\", \"Sex_F_1\"], inplace=True )\n",
        "#data_tabular.drop(columns=[\"MRI_Track_Age_at_Scan\", \"APQ_P_APQ_P_CP\", \"EHQ_EHQ_Total\", \"APQ_P_APQ_P_PM\", \"APQ_P_APQ_P_PP\", \"ColorVision_CV_Score\"], inplace=True )\n",
        "data_tabular.drop(columns=[col for col in data_tabular.columns if col.startswith(\"Basic_Demos_Enroll_Year_\")], inplace=True)\n",
        "data_tabular.drop(columns=[col for col in data_tabular.columns if col.startswith(\"Basic_Demos_Study_Site\")], inplace=True)\n",
        "data_tabular.drop(columns=[col for col in data_tabular.columns if col.startswith(\"Barratt_Barratt_P1_Occ\")], inplace=True)\n",
        "data_tabular.drop(columns=[col for col in data_tabular.columns if col.startswith(\"Barratt_Barratt_P2_Occ\")], inplace=True)\n",
        "data_tabular.drop(columns=[col for col in data_tabular.columns if col.startswith(\"Barratt_Barratt_P1_Edu\")], inplace=True)\n",
        "data_tabular.drop(columns=[col for col in data_tabular.columns if col.startswith(\"Barratt_Barratt_P2_Edu\")], inplace=True)"
      ],
      "metadata": {
        "id": "NReFv-jv0fIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_tabular.shape)\n",
        "data_tabular.columns"
      ],
      "metadata": {
        "id": "ToB5Vm9Hxt8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "170979d3-760c-4ff8-f0f8-9966ce2ba3cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1213, 25)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['participant_id', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV',\n",
              "       'APQ_P_APQ_P_OPD', 'SDQ_SDQ_Conduct_Problems',\n",
              "       'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems',\n",
              "       'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact',\n",
              "       'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing',\n",
              "       'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial', 'ADHD_Outcome', 'Sex_F',\n",
              "       'PreInt_Demos_Fam_Child_Ethnicity_0.0',\n",
              "       'PreInt_Demos_Fam_Child_Ethnicity_1.0',\n",
              "       'PreInt_Demos_Fam_Child_Race_0.0', 'PreInt_Demos_Fam_Child_Race_1.0',\n",
              "       'PreInt_Demos_Fam_Child_Race_2.0', 'PreInt_Demos_Fam_Child_Race_3.0',\n",
              "       'PreInt_Demos_Fam_Child_Race_4.0', 'PreInt_Demos_Fam_Child_Race_7.0',\n",
              "       'PreInt_Demos_Fam_Child_Race_8.0', 'PreInt_Demos_Fam_Child_Race_9.0'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Three methods of local features\n",
        "#path1= /content/drive/MyDrive/Datathon 2025 shared space/Data/Local features/method3_selected_four_features.csv\n",
        "#path2= /content/drive/MyDrive/Datathon 2025 shared space/Data/Local features/top20_from_wrapper_stattest_method2_local_features.csv\n",
        "#path3 = /content/drive/MyDrive/Datathon 2025 shared space/Data/Local features/overlapping_local_features_wrapper_stattest.csv\n",
        "\n",
        "data_local=pd.read_csv('/content/drive/MyDrive/Datathon 2025 shared space/Data/Local features/method3_selected_four_features.csv')\n"
      ],
      "metadata": {
        "id": "SpoYRZkNXhwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_merged=data_tabular.merge(data_local, on=\"participant_id\")"
      ],
      "metadata": {
        "id": "Mn_Jri2XZOds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_merged.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5k2vCZMl4MW",
        "outputId": "e6e68d5f-ccee-45aa-a357-74fd2f15253f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1212, 36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBOOST"
      ],
      "metadata": {
        "id": "fT9deQfmS0BL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode combined target: 2 binary labels â†’ 4 classes (0 to 3)\n",
        "y = data_merged[[\"ADHD_Outcome\", \"Sex_F\"]].apply(lambda row: int(row[\"ADHD_Outcome\"]) * 2 + int(row[\"Sex_F\"]), axis=1)\n",
        "X = data_merged.drop(columns=[\"participant_id\", \"ADHD_Outcome\", \"Sex_F\"])\n",
        "print(y)\n"
      ],
      "metadata": {
        "id": "5X4VVO3YZVr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafbc27e-cf6c-4730-bdf2-ea571e049d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       2\n",
            "1       2\n",
            "2       1\n",
            "3       1\n",
            "4       2\n",
            "       ..\n",
            "1207    1\n",
            "1208    2\n",
            "1209    3\n",
            "1210    2\n",
            "1211    1\n",
            "Length: 1212, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wakmlq52K1hO",
        "outputId": "c5bdaa78-5f1d-42e3-d627-a42e66f8ad23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD',\n",
            "       'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total',\n",
            "       'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing',\n",
            "       'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity',\n",
            "       'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial',\n",
            "       'PreInt_Demos_Fam_Child_Ethnicity_0.0',\n",
            "       'PreInt_Demos_Fam_Child_Ethnicity_1.0',\n",
            "       'PreInt_Demos_Fam_Child_Race_0.0', 'PreInt_Demos_Fam_Child_Race_1.0',\n",
            "       'PreInt_Demos_Fam_Child_Race_2.0', 'PreInt_Demos_Fam_Child_Race_3.0',\n",
            "       'PreInt_Demos_Fam_Child_Race_4.0', 'PreInt_Demos_Fam_Child_Race_7.0',\n",
            "       'PreInt_Demos_Fam_Child_Race_8.0', 'PreInt_Demos_Fam_Child_Race_9.0',\n",
            "       'Current Flow Betweenness_ROI100', 'Eigenvector Centrality_ROI4',\n",
            "       'Eigenvector Centrality_ROI45', 'PageRank_ROI189', 'PageRank_ROI4',\n",
            "       'Degree_ROI126', 'Information Centrality_ROI10',\n",
            "       'Information Centrality_ROI174', 'Information Centrality_ROI38',\n",
            "       'Information Centrality_ROI54', 'Information Centrality_ROI83'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Assume X and y are already defined (X: features, y: target labels)\n",
        "\n",
        "# Split the data (stratified to preserve class balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.1,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Compute class weights and sample weights for training data\n",
        "class_weights = compute_class_weight(class_weight='balanced',\n",
        "                                     classes=np.unique(y_train),\n",
        "                                     y=y_train)\n",
        "class_weights_dict = dict(zip(np.unique(y_train), class_weights))\n",
        "sample_weights = np.array([class_weights_dict[label] for label in y_train])\n",
        "\n",
        "# Instantiate and train the model\n",
        "model = XGBClassifier(\n",
        "    objective=\"multi:softprob\",\n",
        "    num_class=4,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=7,\n",
        "    n_estimators=300,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train, sample_weight=sample_weights)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Test Set Evaluation:\\n\")\n",
        "print(classification_report(y_test, y_pred, digits=3))\n"
      ],
      "metadata": {
        "id": "l4DBVKS9brRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0dbea33-850c-4f64-e845-4c3600ec4153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Evaluation:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.294     0.227     0.256        22\n",
            "           1      0.231     0.176     0.200        17\n",
            "           2      0.571     0.759     0.652        58\n",
            "           3      0.267     0.160     0.200        25\n",
            "\n",
            "    accuracy                          0.459       122\n",
            "   macro avg      0.341     0.331     0.327       122\n",
            "weighted avg      0.412     0.459     0.425       122\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression:\n"
      ],
      "metadata": {
        "id": "Yr7ouyEfxfh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define target and features\n",
        "y_combined = data_merged[[\"ADHD_Outcome\", \"Sex_F\"]]\n",
        "X = data_merged.drop(columns=[\"participant_id\", \"ADHD_Outcome\", \"Sex_F\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_combined,\n",
        "    test_size=0.1,\n",
        "    stratify=y_combined,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Base Logistic Regression model\n",
        "base_lr = LogisticRegression(random_state=42)\n",
        "\n",
        "# Multi-output wrapper\n",
        "multi_lr = MultiOutputClassifier(base_lr)\n",
        "\n",
        "# Pipeline without feature selection\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"classifier\", multi_lr)\n",
        "])\n",
        "\n",
        "# Parameter grid\n",
        "param_grid = {\n",
        "    \"classifier__estimator__C\": [0.01, 0.1, 1.0, 10.0, 100.0],\n",
        "    \"classifier__estimator__penalty\": ['l2'],\n",
        "    \"classifier__estimator__solver\": ['lbfgs'],\n",
        "    \"classifier__estimator__class_weight\": ['balanced', None],\n",
        "    \"classifier__estimator__max_iter\": [1000],\n",
        "}\n",
        "\n",
        "# Cross-validation\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Grid search\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"f1_weighted\",\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "grid.fit(X_train, y_train)\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred, digits=3))"
      ],
      "metadata": {
        "id": "WCYINh59xt1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c4d62a-8f61-46ec-c803-4e25aec0ffb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.868     0.795     0.830        83\n",
            "           1      0.473     0.619     0.536        42\n",
            "\n",
            "   micro avg      0.702     0.736     0.719       125\n",
            "   macro avg      0.671     0.707     0.683       125\n",
            "weighted avg      0.735     0.736     0.731       125\n",
            " samples avg      0.607     0.607     0.590       125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM:"
      ],
      "metadata": {
        "id": "NYZeX8--yQt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y_combined = data_merged[[\"ADHD_Outcome\", \"Sex_F\"]]\n",
        "X = data_merged.drop(columns=[\"participant_id\", \"ADHD_Outcome\", \"Sex_F\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_combined,\n",
        "    test_size=0.1,\n",
        "    stratify=y_combined,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "PSpZf-zgyUP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "\n",
        "# Define parameter grid with correct prefixes\n",
        "param_grid = {\n",
        "    \"classifier__estimator__C\": [0.1, 1.0, 10.0],\n",
        "    \"classifier__estimator__kernel\": ['linear', 'rbf'],\n",
        "    \"classifier__estimator__gamma\": ['scale', 'auto'],\n",
        "    \"classifier__estimator__class_weight\": ['balanced', None]\n",
        "}\n",
        "\n",
        "# K-Fold cross-validation\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Build pipeline with MultiOutputClassifier\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"classifier\", MultiOutputClassifier(SVC(probability=True, random_state=42)))\n",
        "])\n",
        "\n",
        "# Grid search\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"f1_weighted\",\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "y_pred = grid.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, digits=3))"
      ],
      "metadata": {
        "id": "IJ_cuCVRybZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AdaBoost"
      ],
      "metadata": {
        "id": "v1vRItObquOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y_combined = data_merged[[\"ADHD_Outcome\", \"Sex_F\"]]\n",
        "X = data_merged.drop(columns=[\"participant_id\", \"ADHD_Outcome\", \"Sex_F\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_combined,\n",
        "    test_size=0.1,\n",
        "    stratify=y_combined,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Base AdaBoost classifier\n",
        "base_ada = AdaBoostClassifier(random_state=42)\n",
        "\n",
        "# Wrap with MultiOutputClassifier for multi-label output\n",
        "multi_ada = MultiOutputClassifier(base_ada)\n",
        "\n",
        "# Pipeline: scaling + AdaBoost multioutput\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"classifier\", multi_ada)\n",
        "])\n",
        "\n",
        "# Grid search parameter grid\n",
        "param_grid = {\n",
        "    \"classifier__estimator__n_estimators\": [50, 100, 200],\n",
        "    \"classifier__estimator__learning_rate\": [0.01, 0.1, 1.0]\n",
        "}\n",
        "\n",
        "# 5-fold cross-validation setup\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Grid search with f1_weighted scoring\n",
        "grid = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"f1_weighted\",\n",
        "    cv=cv,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit on previously split training data\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best hyperparameters found:\")\n",
        "print(grid.best_params_)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = grid.predict(X_test)\n",
        "\n",
        "# Evaluation report\n",
        "print(\"AdaBoost Classifier Test Set Evaluation:\\n\")\n",
        "print(classification_report(y_test, y_pred, digits=3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0alWeAanqtGh",
        "outputId": "25df4efc-c05d-4c5b-980b-e7df5fb01e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "Best hyperparameters found:\n",
            "{'classifier__estimator__learning_rate': 1.0, 'classifier__estimator__n_estimators': 200}\n",
            "AdaBoost Classifier Test Set Evaluation:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.808     0.964     0.879        83\n",
            "           1      0.474     0.214     0.295        42\n",
            "\n",
            "   micro avg      0.754     0.712     0.733       125\n",
            "   macro avg      0.641     0.589     0.587       125\n",
            "weighted avg      0.696     0.712     0.683       125\n",
            " samples avg      0.652     0.598     0.609       125\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}